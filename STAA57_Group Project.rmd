---
title: "**\\Huge STAA57 Group Project**"
subtitle: "**\\Large What are the dominant research areas in Ontario's automotive sector, and how do institutions specialize in different fields**"
author: "Minh Tran - 1006804914, Swajeet Jadhav - 1009888276"
university: "University of Toronto - Scarborough"
date: "2025-03-15"
output: 
  pdf_document: 
    latex_engine: xelatex
---


```{r, include = FALSE}
# Insert all library required here
library(tidyverse)
library(readxl)
library(dplyr)
library(knitr)
library(kableExtra)
library(pROC)
```

```{r, include = FALSE }
# Read the main data set in as researchers and tags file as researcher_tags

researchers = read.csv("ontarioautoresearchers.csv")
researcher_tags = read_excel("ontarioautoresearcherstags.xls")
```

\pagebreak

# I. Introduction

## Research Goal

With the growing popularity of electric vehicles (EVs) and the rapid advancements in artificial intelligence (AI), particularly in the development of autonomous vehicles like Tesla, it is crucial for automotive research facilities in Ontario to focus their efforts and resources on the right areas. This will ensure a significant contribution to the academia world while assisting the government in implementing effective policies and educational institutions better educate, prepare the next generation of labors. 

This report aims to examine the automotive research areas prioritizing by Ontario's research facilities and identify specialized facilities in trending fields. It will also explore which areas are attracting the most researchers and which institutions are specializing in particular research domains.

## Dataset description

### Data source

Our data set was collected by researchers from the Ministry of Economic Development, Job creation and Trade and was published on the Government of Ontario's public database in 2018. A supporting description table of the research tag will be provided in the Appendix for better understanding of the main data set values. 

**Data set Variables**

```{r, echo=FALSE, eval=TRUE}
glimpse(researchers)
```

Based on a summary of the data set, the `Noise..Viration.and.Harshness` variable was corrupted during the process of uploading or collecting the data and therefore will not be used in our report

```{r, include = FALSE}
# Remove variable with errors
researchers = researchers %>% select(!Noise..Vibration.and.Harshness )
```

Some of the main categorical variables that can help categorizing the data include

- **Researcher.Name**

- **Institution**: Name of university or research center that the researcher works at

- **Research.Areas**: Researcher general field of research

- **Tag**: Researcher's specialized field of research

In addition, the data set also contains research fields as variable (e.g. Alternative Fuels, Autonomy and AI, Vehicle Design) to indicate whether or not a researcher work fall into that field of research

# II. Data Overview Analysis (**Swaaa**)

## *Descriptive Statistic*

-     Firstly lets try and change our data into some numeric values that can help us quantify and hence describe our data.

Let us start by making a table summarizing the Research topics and the number of researchers in each of these fields.  
```{r, echo=FALSE, eval=TRUE}
research_count = researchers %>% group_by(Tag.1) %>%
  summarise(Count = n()) %>%
  mutate(Frequency = Count / sum(Count)) %>%
  arrange(desc(Count))
top_research_field = research_count$Tag.1[1]
kable(research_count, caption = "Summary statistics of research areas")
```
  The above table provides summary statistics of research areas, displaying the number of researchers working in each field ("Count") and their relative proportions ("Frequency").

-   Now for the data we have found it will be interesting to take the top 3 fields from table above and find the top 5 institutions in each of these fields
    -   Firstly the most dominant field of Network and Security
```{r, echo=FALSE, eval=TRUE}
top_institutions = researchers %>%
  filter(Tag.1 == top_research_field) %>%
  count(Institution, sort = TRUE)%>%
  rename(Reseacher_count = n)%>% head(5)
kable(top_institutions, caption = paste("Top 5 Institutions in", top_research_field))
```
  The table above will highlight the top five institutions with the most researchers working in Networks and Security. 

- Let's take the second most dominant field which is Autonomy and AI
```{r, echo=FALSE, eval=TRUE}
research_field2 = research_count$Tag.1[2]
top_institutions = researchers %>%
  filter(Tag.1 == research_field2) %>%
  count(Institution, sort = TRUE)%>%
  rename(Reseacher_count = n)%>% head(5)
kable(top_institutions, caption = paste("Top 5 Institutions in", research_field2))
```


-   Finally the third most trending field of research is Transportation and charging whose table looks like:

```{r, echo=FALSE, eval=TRUE}
research_field3 = research_count$Tag.1[3]
top_institutions = researchers %>%
  filter(Tag.1 == research_field3) %>%
  count(Institution, sort = TRUE)%>%
  rename(Reseacher_count = n)%>% head(5)
kable(top_institutions, caption = paste("Top 5 Institutions in", research_field3))
```
A very interesting observation is the fact that Carleton University has a prominent number of researchers in all three of the top research fields. The most researched field is by far network and security which provides a very cool insight into where the world is heading. The world requires security and more importantly it is most required on the internet as if we are hacked on the internet we can lose a lot of information. Overall, there is a good split between three of the top research fields.

## *Graph & Visualizations*
Graphs are a really important visual representation that helps us visualize how the dat set is distributed it allows us to analyse the variety of variables found in the data and how it relates to other variables across. 

-   Bar chart: Research distribution across institution

```{r, echo=FALSE, eval=TRUE}
 ggplot(researchers %>% count(Institution, sort = TRUE), aes(x = reorder(Institution, n), y = n)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +
  theme_minimal() +
  labs(title = "Research Distribution Across Institutions",
       x = "Institution", y = "Count")
```

-  The title "Research Distribution Across Institutions" clearly indicates the purpose of the graph.
-  The x-axis (Institutions) and y-axis (Counts of Researchers) are labeled appropriately. Let us use the Table 1
-   Pie chart: Proportion of of different research fields

```{r, echo=FALSE, eval=TRUE}
fields = c("Networks and security", "Autonomy and AI", "Transportation and charging",
            "Industrial processes", "Software", "Other")

frequencies = c(0.1229358, 0.0825688, 0.0697248, 0.0623853, 0.0587156, 
                 1 - sum(0.1229358, 0.0825688, 0.0697248, 0.0623853, 0.0587156))

# Create a data frame
df = data.frame(fields, frequencies)

# Create the pie chart
ggplot(df, aes(x = "", y = frequencies, fill = fields)) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar(theta = "y") +
  theme_void() +
  labs(title = "Proportion of Research Fields") +
  scale_fill_manual(values = c("#66c2a5", "#fc8d62", "#8da0cb", "#e78ac3", "#a6d854", "#ffd92f"))
```


-  Each slice represents the proportion of researchers working in that field, based on data aggregated from multiple institutions. These are the top five fields researched and all the other fields combined. A very interesting discovery is the fact that the proportion of the top five fields combined is still less than the proportion of all other fields as we see on the graph in pink.

-   History, frequency of research tag


The graph is a bar chart showing the frequency distribution of different research fields based on the Tag.1 variable.
-  The graph likely has bars of varying heights, showing which research fields are more popular.

# III. Statistical Analysis (**rayaanxsyed**)

```{r, echo=FALSE, eval=TRUE}
research_summary = researchers %>%
  pivot_longer(cols = starts_with("Tag."), names_to = "Tag_Number", values_to =
                 "Research_Area") %>%
  filter(!is.na(Research_Area) & Research_Area != "") %>%
  count(Institution, Research_Area, sort = TRUE) %>%  
  pivot_wider(names_from = Research_Area, values_from = n, values_fill = 0)  
```

We could pick an area we think that will be most trending (AI for example) and test to see if that is true

- Confidence interval for the average number of researcher of all data set institutions
```{r, echo=FALSE, eval=TRUE}
institution_counts = researchers %>%
  count(Institution) %>%
  pull(n)  # Extract only the counts

# Perform t-test to get confidence interval
t_test_result = t.test(institution_counts, conf.level = 0.95)

# Display confidence interval
t_test_result$conf.int
```


-  Let's choose the most trending research topic (Network and security) and do a confidence interval for the average number of researchers in the field.
```{r, echo=FALSE, eval=TRUE}
network_security_count = research_summary$`Networks and security`
# Perform t-test to get confidence interval
t_test_result = t.test(network_security_count, conf.level = 0.95)
# Display confidence interval
t_test_result$conf.int

```

Hypothesis Testing
For the topic (Network and security) and do a hypothesis test for the topic.
```{r, echo=FALSE, eval=TRUE}
network_security_count = research_summary$`Networks and security`
# Perform hypothesis test (H0: mean = 5)
t_test_result = t.test(network_security_count, mu = 5, alternative = "two.sided")

# Display test result
print(t_test_result)
```
Let's pick our highest leading tag and see how it performs in bootstrapped data. We want to observe how it does compared to other tags and if it's the leading tag in all the samples by takign an average. 

```{r, echo=FALSE, eval=TRUE}
# Bootstrapping 

set.seed(50)
research_summary = researchers %>%
  pivot_longer(cols = starts_with("Tag."), names_to = "Tag_Number", values_to = "Research_Area") %>%
  filter(!is.na(Research_Area) & Research_Area != "")  # Sanity Check

num_samples = 1000  # Number of bootstrap samples

bootstrap_results = replicate(num_samples, { # Replicate 1000 times
  sampled_data = research_summary %>% sample_n(n(), replace = TRUE)
  total_researchers = nrow(sampled_data)

  sampled_data %>%
    group_by(Research_Area) %>%
    summarise(Percentage = n() / total_researchers * 100)  # Percentage of each tag
}, simplify = FALSE)

boot_results_df = bind_rows(bootstrap_results, .id = "Iteration") 

average_percentage_df = boot_results_df %>%
  group_by(Research_Area) %>%
  summarise(Mean_Percentage = mean(Percentage)) %>%
  arrange(desc(Mean_Percentage))  # Sort by average percentage in descending order for readability

# Plot the horizontal graph
ggplot(average_percentage_df, aes(x = reorder(Research_Area, Mean_Percentage), y = Mean_Percentage)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  coord_flip() +  # Flip to make it horizontal
  labs(title = "Average Percentage of Researchers in Each Tag",
       x = "Research Area", y = "Average Percentage (%)") +
  theme_minimal()
```
In this graph, the data of the institutions and their tags have been replicated 1000 times. We take the average percentage to see how they perform over the 1000 trials and gain a graph of each tags performance. 


```{r, echo=FALSE, eval=TRUE}
# Confidence Interval for "Networks and security"
network_security_percentage = boot_results_df %>%
  filter(Research_Area == "Networks and security") %>% pull(Percentage)

# 95% confidence interval
lower_ci = quantile(network_security_percentage, 0.025)
upper_ci = quantile(network_security_percentage, 0.975)

cat("95% Confidence Interval for Network and Security: [", lower_ci, ", ", upper_ci, "]\n")

```
By taking a confidence interval for Network and Security, we observe that the true percentage of researchers in Network and Security lies in the interval [ 6.468531, 9.702797 ]. This is a very high value when comparing this to the other tags in our horizontal bar chart. 

Let's examine how Networks and Security performs when compared to the 2nd highest tag (Autonomy and AI) in our bootstrapped data to see if it always leads the data by a hypothesis test.


```{r, echo=FALSE, eval=TRUE}

# 2nd-ranked tag
second_place_tag = average_percentage_df$Research_Area[2]

# Prepare data for paired comparison
paired_data = boot_results_df %>%
  filter(Research_Area %in% c("Networks and security", second_place_tag)) %>%
  pivot_wider(names_from = Research_Area, values_from = Percentage)

# Paired t-test (one-sided: Networks and Security > 2nd place)
t_test_result = t.test(
  paired_data$`Networks and security`,
  paired_data[[second_place_tag]],
  paired = TRUE,
  alternative = "greater"  # Tests if Networks and Security > 2nd place
)

cat("Paired t-test: Networks and Security vs.", second_place_tag, "\n")
cat("Mean % Network and Security:", mean(paired_data$`Networks and security`), "\n")
cat("Mean % (", second_place_tag, "):", mean(paired_data[[second_place_tag]]), "\n")
cat("T-statistic:", t_test_result$statistic, "\n")
cat("P-value:", t_test_result$p.value, "\n")

if (t_test_result$p.value < 0.05) {
  cat("Reject H₀. Networks and Security is significantly higher than the other tags. (p < 0.05).")
} else {
  cat("No significant difference (p ≥ 0.05).")
}
```
Based off our paired t-test, we get a average Network Security score of 8.001923 and a average Autonomy and AI score of 6.806818. Since the averages are distant, we can expect a large t statistic and a small p value. 

We observe a t statistic value of 31.29503 and a extremely small p value 1.070572e-150 (p < 0.05), rejecting the null hypothesis and observing Networks and Security is significantly higher than the other tags.

- Bootstrapping is a re sampling technique used to estimate statistics on a dataset by repeatedly sampling with replacement. It helps assess the variability of an estimator (e.g., mean, standard deviation) and construct confidence intervals without relying on strong parametric assumptions. Do bootstrapping on network and security.  
```{r, echo=FALSE, eval=TRUE}
# Bootstrapping function
boot_function = function() {
  boot_data = sample(network_security_count, size =
                       length(network_security_count), replace = TRUE)
  return(mean(boot_data, na.rm = TRUE))
}
# Compute 95% Confidence Interval using Bootstrapping (1000 replications)
boot_CI =quantile(replicate(1000, boot_function()), c(0.025, 0.975))
# Print results
print(boot_CI)
# Now lets compare with t-test confidence interval
t.test(network_security_count)

```

# IV. Predictive modeling (Regression) (**Minh**)

**1. Logistic Regression Model**

*1.1. Model explanation*

The allocation of research funding plays a pivotal role in identifying key research fields that attract the attention of funding bodies such as Canada Research Chair Program and other major investors. These funding trend are essential indicators of the areas prioritized by the Canadian government and industry stakeholders in the automotive sector. Understanding these trends can provide insight into the direction of research investment, thereby influencing strategic decision in academia and industry alike.

To analyze the factors influencing research funding, we employed a logistic regression model with the primary dependent variable being **is_Funded**. This variable take a value of 1 if the research has secured funding from the Canada Research Chair program or other similar grants, and 0 otherwise. The independent variables include various research's primary fields as categorized in **Tag.1** column of the data set.

*1.2. Result and Key Findings*
```{r, include=FALSE}
reg_data = na.omit(researchers)
#This code chunk dynamically create a dummy variable for all research field columns 

# Dynamically get all research field indicating columns after "Tag.5 column"
start_col = which(names(reg_data) == "Tag.5") + 1
research_indicator_col = names(reg_data)[start_col:length(names(reg_data))]

# Add new summary variables for each of the research field indicating columns
for (col in research_indicator_col){
  new_col_name = paste0("is_", col)
  reg_data[[new_col_name]] = ifelse(tolower(reg_data[["Tag.1"]])==tolower(gsub("\\."," ", col)),1,0)
}

reg_data=reg_data%>%
  mutate(is_Funded = ifelse(Research.Chairs.Grant.Funding!="",1,0))

reg_data = reg_data %>% select(contains("is_"))
```
**Table : Regression Model Result Summary**
```{r, echo=FALSE, eval=TRUE}
# Logistic regression model

regression = glm(is_Funded ~., family = binomial, data = reg_data)
summary (regression)

reg_result = data.frame(coefficient = coef(regression), 
                        odd = ceiling(exp(coef(regression)) * 10^2)/10^2)

reg_result = reg_result %>% arrange(desc(coefficient))

```

**Table : Regression Model Coefficient**
```{r, echo=FALSE, eval=TRUE}
kable(reg_result)
```

A substantial proportions of the variables int he model exhibit high **p-value** of greater than 5% suggesting that most of the research fields are not statistically significant predictors of whether a research project will be funded. This is likely due to the limited number of observations available int he data set, which may have constrained the model's ability to detect more nuanced relationships. Nevertheless, the model provides valuable insights into general trends in funding allocation by the Canadian government and major investors.

Despite the high **p-value** for many variables, certain research fields stood out interns of their impact on the funding probabilities. Specifically, **Forming and Joining**, **Alternative Fuels**, and **Internal Combustion Engines** demonstrated relatively high log-odds ratios. These fields exhibited 4 to 5 times higher odds of receiving funding than those in other areas. In addition, **is_Forming.and.Joining** and **is_Alternative.Fuels** variables were both statistically significant with p-values of approximately 4% and 10% respectively which further support the findings above.

The significance and high odd of **Forming and Joining** research fields aligns with ongoing research efforts to improve manufacturing process which are crucial for the production of commercial vehicles. While the corresponding number for **Alternative Fuels** underscores the importance of environmentally sustainable technologies, which are increasingly emphasized in both governmental policy and industry innovation.

**2) Cross validation**

To further evaluate the robustness of the logistic regression model, we conducted a k-fold cross-validation with four folds.

The results are as follow:
```{r, echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE}

k = 4

reg_validation = reg_data %>% mutate(group_ind = sample(c(1:k), size=nrow(reg_data),
                                                  replace = T))

c.index = vector()

for (i in 1:k){
  reg_data.train = reg_validation %>% filter(group_ind != i)
  reg_data.test = reg_validation %>% filter(group_ind == i)
  logit.mod = glm(is_Funded ~ ., family = binomial, data = reg_data.train)
  pi_hat = predict(logit.mod, newdata=reg_data.test, type="response")
  m.roc=roc(reg_data.test$is_Funded ~ pi_hat)
  c.index[i] = auc(m.roc)
}
cat("AUC score:",c.index )

cat("Average AUC score:", mean(c.index))
```

The model predictive performance assessed using the AUC score. The resulting average AUC score was 0.609, which suggests a fair to somewhat weak performance. This moderate performance is likely attributed to the large number of non-significant variables in the model, reflecting the challenges posed by limited data. Nevertheless, the model remains useful for identifying general funding trends rather than providing highly accurate predictions for individual research projects. It serves its purpose of illustrating that dominant research areas that are attracting funding, which is the primary objective of the analysis.

# V. Summary

In conclusion...

The logistic regression analysis provides valuable insights into the research funding landscape within the Canadian automotive sector. The significant fields of **Forming and Joining** and **Alternative Fuels**, along with the notable importance of **Internal Combustion Engines**, underscore the ongoing focus on traditional automotive manufacturing processes and sustainable technologies. These finding aligns with the broader trends observed in the automotive industry, where there is increasing attention to environmentally friend alternatives to conventional fuels and more efficient manufacturing practices.

However, as the market of Autonomous Vehicles and Electric Vehicles grows, we believe that more resources should be reallocate to support researches in these emerging areas. Fields such as **Autonomy and AI**, **Batteries and Fuel Cells**, and **Hybrid and Electric Vehicles** are expected to play a pivotal role in shaping the future of automotive industry.
# Appendix

