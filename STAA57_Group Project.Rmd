---
title: "STAA57 Group Project"
subtitle: "What are the dominant research areas in Ontario's automotive sector, and how do institutions specialize in different fields?"
author: "Minh Tran - 1006804914, Rayaan Syed - 1010231081"
university: "University of Toronto - Scarborough"
date: "March 15, 2025"
output: pdf_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include = FALSE}
# Insert all library required here
library(tidyverse)
library(readxl)
library(dplyr)
library(knitr)
library(kableExtra) 
library(ggplot2)
```

```{r, include = FALSE }
# Read the main data set in as researchers and tags file as researcher_tags

researchers = read.csv("ontarioautoresearchers.csv")
researcher_tags = read_excel("ontarioautoresearcherstags.xls")
```

\pagebreak

# I. Introduction

## Research Goal

With the growing popularity of electric vehicles (EVs) and the rapid advancements in artificial intelligence (AI), particularly in the development of autonomous vehicles like Tesla, it is crucial for automotive research facilities in Ontario to focus their efforts and resources on the right areas. This will ensure a significant contribution to the academia world while assisting the government in implementing effective policies and educational institutions better educate, prepare the next generation of labors. 

This report aims to examine the automotive research areas prioritizing by Ontario's research facilities and identify specialized facilities in trending fields. It will also explore which areas are attracting the most researchers and which institutions are specializing in particular research domains.

## Dataset description

### Data source

Our dataset was collected by researchers from teh Ministry of Economic Development, Job creation and Trade and was published on the Government of Ontario's public database in 2018.

**Table 1: Data set Variables**

```{r, echo=FALSE, eval=TRUE}
glimpse(researchers)
```

Based on a summary of the data set, the `Noise..Viration.and.Harshness` variable was corrupted during the process of uploading or collecting the data and therefore will not be used in our report

```{r}
# Remove variable with errors

researchers = researchers %>% select(!Noise..Vibration.and.Harshness )

# We removed Brock University, Lakehead University, Royal Military College, and Laurentian University from our dataset as each contained less than two entries. These universities likely did not report their full research info to the dataset collectors, thus we removed it to maintain accuracy. 

researchers <- researchers %>% filter(!Institution %in% c("Brock University", "Lakehead University", "Laurentian University", "Royal Military College"))

```

Some of the main categorical variables that can help categorizing the data include

- **Researcher.Name**

- **Institution**: Name of university or research center that the researcher works at

- **Research.Areas**: Researcher general field of research

- **Tag**: Researcher's specialized field of research

In addition, the data set also contains research fields as variable (e.g. Alternative Fuels, Autonomy and AI, Vehicle Design) to indicate whether or not a researcher work fall into that field of research

# II. Data Overview Analysis

## *Descriptive Statistic*

From our dataset, we are able to extract the disparity of researchers across fields of research. This would include research fields such as "Network and Security", "Autonomy and AI", "Nanotechnology", and other vehicle-related fields.  
    
    
```{r,echo=FALSE}
# Identifying the amount of researchers across the fields of automotive design.
research_summary = researchers %>%
  pivot_longer(cols = starts_with("Tag."), names_to = "Tag_Number", values_to = "Research_Area") %>%
  filter(!is.na(Research_Area) & Research_Area != "") %>%  # Sanity check
  count(Institution, Research_Area, sort = TRUE) %>%  # Count occurrences
  pivot_wider(names_from = Research_Area, values_from = n, values_fill = 0)  # Use wide format

print(research_summary)

```
  Upon reviewing the table, the three leading researching fields are "Networks and Security", "Autonomy and AI", and "Polymers and Composite Materials". The universities have reported 50+ researchers working in these ares which would indicate there is significant progress being made. On the contrast, "Crashworthiness" and "Mechatronics" are among the least studied fields with less than 10 researchers total.
  
  
  
We now check for the dominating research field for each university. The table below is generated by finding the max researchers in an institution across a research field. 
    
    
```{r,echo=FALSE}
# Identifying the dominant field for each university
    
research_summary$Institution = research_summary$Institution %>%
  str_to_title() %>%  # Brief sanity check to make sure institution strings are one. 
  str_trim()    # Ex. "Ryerson University" should be equal to "Ryerson university    " 


top_research_by_uni = research_summary %>%
  pivot_longer(cols = -Institution, names_to = "Research_Area", values_to = "Count") %>%
  group_by(Institution) %>%
  slice_max(Count, n = 1, with_ties = FALSE) %>%  # Get the top research category per institution
  select(Institution, Research_Area)

print(top_research_by_uni)

```
  From the table, the universities are associated with their highest producing research field. Several universities are mostly researching "Networks and Security" like Carleton University, University of Waterloo, University of Ontario Institute of Technology. 
  
  This information can also be crucial to understand how the fields with low researchers from the previous table are not being targeted enough by the universities.
  
  
  

We now check for the percentage breakdown of the university's dominating research field and their contribution as a whole. This is important to understand the concentration of university's in specific fields and whether some diversification can be made to the university.     
```{r, echo= FALSE}
# Identifying percentage breakdown of each university and their study on each field. 

research_summary = research_summary %>%
  mutate(Total_Research = rowSums(across(-Institution)))  # Sum all research areas per university

top_research_by_uni = research_summary %>%
  pivot_longer(cols = -c(Institution, Total_Research), names_to = "Research_Area", values_to = "Count") %>%
  mutate(Percentage = (Count / Total_Research) * 100) %>%  # Find percentage
  group_by(Institution) %>%
  slice_max(Count, n = 1, with_ties = FALSE) %>%  # Get top research area per institution
  select(Institution, Research_Area, Count, Percentage) %>% arrange(desc(Percentage)) # We want descending order for readability
top_research_by_uni


```

From the table, we see that Carleton University, York University, and University of Ottawa have 20%+ of their research contributions among their highest fields. Waterloo University and University Of Ontario Institute Of Technology have the most diversification as well as high amounts of researchers across several fields. 

## *Graph & Visualizations*

-   Bar chart: Research distribution across institution
-   Pie chart: Proportion of of different research fields
-   History, frequency of research tag

# III. Statistical Analysis

Let's pick our highest leading tag and see how it performs in bootstrapped data. We want to observe how it does compared to other tags and if it's the leading tag in all the samples by taking an average. 

```{r, echo= FALSE}
# Bootstrapping 

set.seed(50)
research_summary = researchers %>%
  pivot_longer(cols = starts_with("Tag."), names_to = "Tag_Number", values_to = "Research_Area") %>%
  filter(!is.na(Research_Area) & Research_Area != "")  # Sanity Check

num_samples = 1000  # Number of bootstrap samples

bootstrap_results = replicate(num_samples, { # Replicate 1000 times
  sampled_data = research_summary %>% sample_n(n(), replace = TRUE)
  total_researchers = nrow(sampled_data)

  sampled_data %>%
    group_by(Research_Area) %>%
    summarise(Percentage = n() / total_researchers * 100)  # Percentage of each tag
}, simplify = FALSE)

boot_results_df = bind_rows(bootstrap_results, .id = "Iteration") 

average_percentage_df = boot_results_df %>%
  group_by(Research_Area) %>%
  summarise(Mean_Percentage = mean(Percentage)) %>%
  arrange(desc(Mean_Percentage))  # Sort by average percentage in descending order for readability

# Plot the horizontal graph
ggplot(average_percentage_df, aes(x = reorder(Research_Area, Mean_Percentage), y = Mean_Percentage)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  coord_flip() +  # Flip to make it horizontal
  labs(title = "Average Percentage of Researchers in Each Tag",
       x = "Research Area", y = "Average Percentage (%)") +
  theme_minimal()
```
In this graph, the data of the institutions and their tags have been replicated 1000 times. We take the average percentage to see how they perform over the 1000 trials and gain a graph of each tags performance. By inspection, "Networks and Security" and "Autonomy and AI" lead from our 1000 samples. 


```{r, echo= FALSE}

# Finding 95% Confidence Interval of Each Research Area
ci_table <- boot_results_df %>%
  group_by(Research_Area) %>%
  summarise(
    Mean_Percentage = mean(Percentage, na.rm = TRUE),
    Lower_CI = quantile(Percentage, 0.025, na.rm = TRUE),
    Upper_CI = quantile(Percentage, 0.975, na.rm = TRUE)
  )

ggplot(ci_table, aes(x = reorder(Research_Area, Mean_Percentage), y = Mean_Percentage)) +
  geom_point(color = "blue", size = 3) +  # Mean values as points
  geom_errorbar(aes(ymin = Lower_CI, ymax = Upper_CI), width = 0.2, color = "red") +
  coord_flip() +  
  labs(
    title = "95% Confidence Intervals for Research Areas",
    x = "Research Area",
    y = "Mean Percentage"
  ) +
  theme_minimal()


```
By taking confidence intervals for each research tag, we gain data regarding the ranges of each tag within the 1000 trials. While "Networks and Security" leads the dataset by inspection, the CI interval overlaps with "Autonomy and AI". It is necessary to verify if in any of the 1000 trials if "Networks and Security" loses even once to "Autonomy and AI" to conclude it always leads in our dataset. 

Let's examine how "Networks and Security" performs when compared to the 2nd highest tag (Autonomy and AI) in the bootstrapped data to see if it leads in the hypothesis test.


```{r, echo= FALSE}
# 2nd-ranked tag
second_place_tag = average_percentage_df$Research_Area[2]

# Prepare data for t-test
network_data = boot_results_df %>%
  filter(Research_Area == "Networks and security") %>%
  pull(Percentage)

second_place_data = boot_results_df %>%
  filter(Research_Area == second_place_tag) %>%
  pull(Percentage)

# t-test to show Networks and Security > 2nd place
t_test_result = t.test(
  network_data,
  second_place_data,
  alternative = "greater"  
)

cat("Independent t-test: Networks and Security vs.", second_place_tag, "\n")
cat("Mean % Network and Security:", mean(network_data), "\n")
cat("Mean % (", second_place_tag, "):", mean(second_place_data), "\n")
cat("T-statistic:", t_test_result$statistic, "\n")
cat("P-value:", t_test_result$p.value, "\n") # Print results

if (t_test_result$p.value < 0.05) {
  cat("Reject H0. Networks and Security is significantly higher than the other tags. (p < 0.05).")
} else {
  cat("No significant difference (p >= 0.05).") # Check hypothesis
}


```
Based off our t-test, we get a "Networks and Security" mean of 8.001923 and an "Autonomy and AI" mean of 6.806818. Since the averages are distant, we can expect a large t- statistic and a small p value. 

We observe a t statistic value of 33.42531 and a extremely small p value 3.359765e-195  (p < 0.05), rejecting the null hypothesis and observing "Networks and Security" is significantly higher than the other tags. We conclude that "Networks and Security" always wins in comparison to other research tags.

